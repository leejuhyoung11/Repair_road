{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Repair_Road.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vhWYZnTKGayO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leejuhyoung11/Repair_road/blob/master/Repair_Road.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG--LzZLGEDz",
        "colab_type": "code",
        "outputId": "a7328668-1094-4e1a-c2f9-fc1e52e18664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)\n",
        "root_path = 'gdrive/My Drive/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS2o-Nd1ofFN",
        "colab_type": "text"
      },
      "source": [
        "### VGGNet.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-CV3cx_ohJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models.vgg as vgg\n",
        "\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)\n",
        "\n",
        "cfg = [32,32,'M', 64,64,128,128,128,'M',256,256,256,512,512,512,'M'] #13 + 3 =vgg16\n",
        "\n",
        "    \n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
        "        super(VGG, self).__init__()\n",
        "        \n",
        "        self.features = features #convolution\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),  \n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )#FC layer\n",
        "        \n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x) #Convolution \n",
        "        x = self.avgpool(x) # avgpool\n",
        "        x = x.view(x.size(0), -1) #\n",
        "        x = self.classifier(x) #FC layer\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')  \n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)  \n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 200\n",
        "    \n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, padding = 1)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "                     \n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "vgg = make_layers(cfg)\n",
        "\n",
        "\n",
        "\n",
        "vgg16 = VGG(vgg, 10, True).to(device)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhWYZnTKGayO",
        "colab_type": "text"
      },
      "source": [
        "### Alexnet.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrG5KsE8GMnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(200, 32, kernel_size=5, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding = 1),\n",
        "            nn.Conv2d(32, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding = 1),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding = 1),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8P-6hlrGfo8",
        "colab_type": "text"
      },
      "source": [
        "### learn.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpzLDgN5GkAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.ndimage.interpolation import zoom\n",
        "\n",
        "class Learn(object):\n",
        "    def __init__(self):\n",
        "        self.images = []  # 이미지 데이터를 담아둘 배열 생성\n",
        "\n",
        "    def show_images(self):  # 이미지 데이터가 정상적으로 읽어지는지 보여준다\n",
        "        for i in self.images:\n",
        "            cv2.imshow('images', i[0])  # 윈도우에 사진 띄우기\n",
        "            cv2.waitKey(8)  # 윈도우 대기 시간\n",
        "        cv2.destroyAllWindows()  # 윈도우 종료\n",
        "\n",
        "    def import_label(self, label_path):  # 라벨이 들어있는 파일을 읽어와 라벨 배열에 담아준다\n",
        "        file = open(label_path)  # 라벨파일을 열음\n",
        "        file = file.read().split()  # 라벨파일을 스플릿해서 읽음\n",
        "        label_array=[]  # 라벨을 담아줄 배열 생성\n",
        "        for label in file:\n",
        "            label_array.append(label)  # 스플릿한 라벨을 배열에 넣어줌\n",
        "        return label_array\n",
        "\n",
        "    def import_label_forColab(self, label_path):  # 라벨이 들어있는 파일을 읽어와 라벨 배열에 담아준다\n",
        "        # file = open(label_path) # 라벨파일을 열음\n",
        "        # file = file.read().split() # 라벨파일을 스플릿해서 읽음\n",
        "        label_array = ['clean_road', 'cracked_road', 'perforated_road']  # 라벨을 담아줄 배열 생성\n",
        "        # for label in file:\n",
        "        #    label_array.append(label) # 스플릿한 라벨을 배열에 넣어줌\n",
        "        return label_array\n",
        "\n",
        "    def find_index(self, label_arr, key):  # 라벨명의 인덱스로 라벨링을 하기 위해 인덱스를 찾아준다\n",
        "        for index, value in enumerate(label_arr):\n",
        "            if value == key:\n",
        "                return index\n",
        "            else:\n",
        "              print(value)\n",
        "\n",
        "    def import_dataset(self, train_path, label_path):  # 이미지를 불러와서 제너럴 데이터폼으로 바꾼다\n",
        "        print('image loading...')\n",
        "        label = self.import_label(label_path)  # 라벨을 불러와서 배열에 담음\n",
        "        for image_data in glob.glob(train_path):  # 절대경로 안에 있는 모든 이미지를 불러옴\n",
        "            # print(image_data)\n",
        "\n",
        "            try:  # 불량 데이터를 거르기위한 트라이 익셉트\n",
        "                image = cv2.resize(cv2.imread(image_data)/255, dsize=(200, 200))  # 불러온 이미지를 0~1사이값으로 바꾼뒤 리사이즈함\n",
        "                #rotate30 = cv2.getRotationMatrix2D((100, 100), 30, 1)  # 이미지를 부풀리기위해 로테이트해줌\n",
        "                #rotate45 = cv2.getRotationMatrix2D((100, 100), 45, 1)\n",
        "                # move = np.float32([1, 0, np.random.randint(100)], [0, 1, np.random.randint(100)])  # error;;;\n",
        "                #image2 = cv2.warpAffine(image, rotate30, (200, 200))  # 로테이트한 이미지 생성\n",
        "                #image3 = cv2.warpAffine(image, rotate45, (200, 200))\n",
        "                #image4 = cv2.flip(image, 1)  # 좌우반전\n",
        "                #image5 = cv2.flip(image, 1)  # 상하반전\n",
        "                # image6 = cv2.warpAffine(image, move, (200, 200))\n",
        "            except:\n",
        "                print('please remove image : ', image_data)\n",
        "\n",
        "            self.images.append((image, self.find_index(label, image_data.split('\\\\')[-2])))  # 위에서 생성한 배열에 텐서로 변환해서 데이터를 담아줌\n",
        "            #self.images.append((image2, self.find_index(label, image_data.split('\\\\')[-2])))  # 로테이트한 데이터도 z담아줌\n",
        "            #self.images.append((image3, self.find_index(label, image_data.split('\\\\')[-2])))\n",
        "            #self.images.append((image4, self.find_index(label, image_data.split('\\\\')[-2])))  # 반전한 데이터도 담아줌\n",
        "            #self.images.append((image5, self.find_index(label, image_data.split('\\\\')[-2])))\n",
        "            # self.images.append((image6, self.find_index(label, image_data.split('\\\\')[-2])))\n",
        "        return self.images\n",
        "\n",
        "\n",
        "    def import_dataset_forColab(self, train_path, label_path):  # 이미지를 불러와서 제너럴 데이터폼으로 바꾼다\n",
        "        label = self.import_label_forColab(label_path)  # 라벨을 불러와서 배열에 담음\n",
        "        for image_data in glob.glob(train_path):  # 절대경로 안에 있는 모든 이미지를 불러옴\n",
        "            images = cv2.imread(image_data)\n",
        "            try:  # 불량 데이터를 거르기위한 트라이 익셉트\n",
        "                image = cv2.resize(cv2.imread(image_data) / 255, dsize=(200, 200))  # 불러온 이미지를 0~1사이값으로 바꾼뒤 리사이즈함\n",
        "\n",
        "            except:\n",
        "                print('please remove image : ', image_data)\n",
        "\n",
        "            self.images.append(\n",
        "                (image, self.find_index(label, image_data.split('/')[-2])))  # 위에서 생성한 배열에 텐서로 변환해서 데이터를 담아줌\n",
        "\n",
        "        return self.images\n",
        "\n",
        "   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5ySmdLvGmEJ",
        "colab_type": "text"
      },
      "source": [
        "### main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC9JR-81GqcX",
        "colab_type": "code",
        "outputId": "2ae532dc-e7be-4cc4-83b1-105da525c194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "#from AlexNet import AlexNet as Net\n",
        "#from learn import Machine_Learning as Learn\n",
        "\n",
        "# define\n",
        "batch_size = 32  # 배치 사이즈\n",
        "number_of_epoch = 1000  # 에포크 반복 횟수\n",
        "#### Pycharm ####\n",
        "# path = 'C:/Users/gjb26/OneDrive/AIprj/prj'\n",
        "# train_path = path + '/train/*/*'  # 이미지 데이터셋이 들어있는 절대경로\n",
        "# test_path = path + '/test/*/*'  # 이미지 데이터셋이 들어있는 절대경로\n",
        "# label_path = './label.txt'  # 라벨파일의 상대경로\n",
        "\n",
        "#### colab ####\n",
        "train_path = '/content/gdrive/My Drive/road/train/*/*' # 이미지 데이터셋이 들어있는 절대경로\n",
        "test_path = '/content/gdrive/My Drive/road/test/*/*' # 이미지 데이터셋이 들어있는 절대경로\n",
        "label_path = '/content/gdrive/My Drive/road/label.txt' # 라벨파일의 상대경로\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    training = Learn()  # 객체 생성\n",
        "    test = Learn()\n",
        "\n",
        "    #### pycharm ####\n",
        "    # training.import_dataset(train_path, label_path)  # 데이터셋을 불러옴\n",
        "    # test.import_dataset(test_path, label_path)\n",
        "\n",
        "    #### colab ####\n",
        "    training.import_dataset_forColab(train_path, label_path)\n",
        "    test.import_dataset_forColab(test_path, label_path)\n",
        "\n",
        "    # learn.show_images() # 데이터셋이 잘 읽어지는지 확인\n",
        "    # print(learn.images)\n",
        "\n",
        "    train_dataset = training.images\n",
        "    test_dataset = test.images\n",
        "\n",
        "    # batch size : 32, shffle 사용을 통해 임의의 data 선택\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    is_cuda = False\n",
        "    if torch.cuda.is_available():  # GPU가 사용가능한지 확인\n",
        "        is_cuda = True  # GPU가 사용 가능하면 학습을 GPU로함\n",
        "\n",
        "    #model = VGG()\n",
        "    #model = model.to(device)\n",
        "    if is_cuda:\n",
        "        model.cuda()\n",
        "\n",
        "\n",
        "    ###  AlexNet ###\n",
        "    # criterion = nn.CrossEntropyLoss()\n",
        "    # # optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\n",
        "    # lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9) \n",
        "\n",
        "    # for epoch in range(350):  # loop over the dataset multiple times\n",
        "    #     running_loss = 0.0\n",
        "    #     lr_sche.step()\n",
        "\n",
        "    #     for i, (data, labels) in enumerate(train_loader, 0):\n",
        "    #         # get the inputs\n",
        "\n",
        "    #         inputs, labels = data.cuda(), labels.cuda()\n",
        "    #         # print(inputs)\n",
        "\n",
        "    #         # zero the parameter graients\n",
        "    #         optimizer.zero_grad()\n",
        "\n",
        "    #         # forward + backward + optimize\n",
        "    #         outputs = model(inputs.float())\n",
        "    #         loss = criterion(outputs, labels)\n",
        "    #         loss.backward()\n",
        "    #         optimizer.step()\n",
        "\n",
        "    #         # print statistics\n",
        "    #         running_loss += loss.item()\n",
        "    #         # if i % 10 == 9:  # 1000 batch 마다 loss 출력\n",
        "    #     print('[%d, %5d] loss: %.10f' % (epoch + 1, (i + 1), running_loss / 1000))\n",
        "    #     running_loss = 0.0\n",
        "\n",
        "    # print('Finished Training')\n",
        "\n",
        "    # # performance on the whole test dataset\n",
        "    # correct = 0\n",
        "    # total = 0\n",
        "    # clean = 0\n",
        "    # clean_total = 0\n",
        "    # cracked = 0\n",
        "    # cracked_total = 0\n",
        "    # perforated = 0\n",
        "    # perforated_total = 0\n",
        "    # classes = [0, 0, 0]\n",
        "    # bingo = [0, 0, 0]\n",
        "\n",
        "    # with torch.no_grad():\n",
        "    #     for (data, labels) in test_loader:\n",
        "    #         images, labels = Variable(data.cuda()), Variable(labels.cuda())\n",
        "    #         outputs = model(images.float())\n",
        "    #         _, predicted = torch.max(outputs.data, 1)\n",
        "    #         total += labels.size(0)\n",
        "    #         correct += (predicted == labels).sum().item()\n",
        "    #         # print(labels[1].item())\n",
        "    #         for i in range(batch_size):  # 종류별로 정확도를 출력하기 위한 반복문\n",
        "    #             try:\n",
        "    #                 label = labels[i]  # 라벨과 예측값을 인덱스로 비교\n",
        "    #                 pred = predicted[i]\n",
        "    #                 # print(label.item())\n",
        "    #                 if label.item() == 0:\n",
        "    #                     clean_total += 1\n",
        "    #                     if pred.item() == 0:\n",
        "    #                         clean += 1\n",
        "    #                 elif label.item() == 1:\n",
        "    #                     cracked_total += 1\n",
        "    #                     if pred.item() == 1:\n",
        "    #                         cracked += 1\n",
        "    #                 elif label.item() == 2:\n",
        "    #                     perforated_total += 1\n",
        "    #                     if pred.item() == 2:\n",
        "    #                         perforated += 1\n",
        "    #             except:\n",
        "    #                 print('index error')  # 아직 인덱스를 동적으로 처리하지 못해서 트라이 캐치로 커버함\n",
        "    # print('Accuracy of clean : {}%'.format(100 * clean / clean_total))\n",
        "    # print('Accuracy of cracked : {}%'.format(100 * cracked / cracked_total))\n",
        "    # print('Accuracy of perforated : {}%'.format(100 * perforated / perforated_total))\n",
        "    # print('Accuracy of test images: %d %%' % (100 * correct / total))\n",
        "\n",
        "\n",
        "\n",
        "    ###  VGGNet  ###\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = torch.optim.SGD(vgg16.parameters(), lr = 0.005,momentum=0.9)\n",
        "    lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
        "    \n",
        "    for epoch in range(350):  # loop over the dataset multiple times\n",
        "        running_loss = 0.0\n",
        "        lr_sche.step()\n",
        "        for i, (data, labels) in enumerate(train_loader, 0):\n",
        "            # get the inputs\n",
        "\n",
        "            inputs, labels = data.cuda(), labels.cuda()\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter graients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = vgg16(inputs.float())\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            # if i % 10 == 9:  # 1000 batch 마다 loss 출력\n",
        "        print('[%d, %5d] loss: %.10f' % (epoch + 1, (i + 1), running_loss / 1000))\n",
        "        running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "    \n",
        "    # performance on the whole test dataset\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    clean = 0\n",
        "    clean_total = 0\n",
        "    cracked = 0\n",
        "    cracked_total = 0\n",
        "    perforated = 0\n",
        "    perforated_total = 0\n",
        "    classes = [0, 0, 0]\n",
        "    bingo = [0, 0, 0]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (data, labels) in test_loader:\n",
        "            images, labels = Variable(data.cuda()), Variable(labels.cuda())\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = vgg16(images.float())\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            # print(labels[1].item())\n",
        "            for i in range(batch_size):  # 종류별로 정확도를 출력하기 위한 반복문\n",
        "                try:\n",
        "                    label = labels[i]  # 라벨과 예측값을 인덱스로 비교\n",
        "                    pred = predicted[i]\n",
        "                    # print(label.item())\n",
        "                    if label.item() == 0:\n",
        "                        clean_total += 1\n",
        "                        if pred.item() == 0:\n",
        "                            clean += 1\n",
        "                    elif label.item() == 1:\n",
        "                        cracked_total += 1\n",
        "                        if pred.item() == 1:\n",
        "                            cracked += 1\n",
        "                    elif label.item() == 2:\n",
        "                        perforated_total += 1\n",
        "                        if pred.item() == 2:\n",
        "                            perforated += 1\n",
        "                except:\n",
        "                    print('index error')  # 아직 인덱스를 동적으로 처리하지 못해서 트라이 캐치로 커버함\n",
        "    print('Accuracy of clean : {}%'.format(100 * clean / clean_total))\n",
        "    print('Accuracy of cracked : {}%'.format(100 * cracked / cracked_total))\n",
        "    print('Accuracy of perforated : {}%'.format(100 * perforated / perforated_total))\n",
        "    print('Accuracy of test images: %d %%' % (100 * correct / total))\n",
        "    \n",
        "    \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "cracked_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "please remove image :  /content/gdrive/My Drive/road/test/cracked_road/56.tech03-1.gif\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n",
            "clean_road\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,    24] loss: 0.0243457812\n",
            "[2,    24] loss: 0.0243460197\n",
            "[3,    24] loss: 0.0199522513\n",
            "[4,    24] loss: 0.0187673334\n",
            "[5,    24] loss: 0.0180053377\n",
            "[6,    24] loss: 0.0171073646\n",
            "[7,    24] loss: 0.0169651890\n",
            "[8,    24] loss: 0.0165712131\n",
            "[9,    24] loss: 0.0165837182\n",
            "[10,    24] loss: 0.0173584562\n",
            "[11,    24] loss: 0.0147077402\n",
            "[12,    24] loss: 0.0181985097\n",
            "[13,    24] loss: 0.0169327059\n",
            "[14,    24] loss: 0.0153823912\n",
            "[15,    24] loss: 0.0144407312\n",
            "[16,    24] loss: 0.0141003569\n",
            "[17,    24] loss: 0.0140082286\n",
            "[18,    24] loss: 0.0146901595\n",
            "[19,    24] loss: 0.0131801275\n",
            "[20,    24] loss: 0.0151132638\n",
            "[21,    24] loss: 0.0136463716\n",
            "[22,    24] loss: 0.0132761980\n",
            "[23,    24] loss: 0.0130903818\n",
            "[24,    24] loss: 0.0114123375\n",
            "[25,    24] loss: 0.0116752827\n",
            "[26,    24] loss: 0.0129679841\n",
            "[27,    24] loss: 0.0123970951\n",
            "[28,    24] loss: 0.0122980612\n",
            "[29,    24] loss: 0.0113801727\n",
            "[30,    24] loss: 0.0111967082\n",
            "[31,    24] loss: 0.0103677672\n",
            "[32,    24] loss: 0.0120458026\n",
            "[33,    24] loss: 0.0119291825\n",
            "[34,    24] loss: 0.0108180869\n",
            "[35,    24] loss: 0.0102253373\n",
            "[36,    24] loss: 0.0108949337\n",
            "[37,    24] loss: 0.0105081315\n",
            "[38,    24] loss: 0.0106273124\n",
            "[39,    24] loss: 0.0107677736\n",
            "[40,    24] loss: 0.0099906424\n",
            "[41,    24] loss: 0.0121601638\n",
            "[42,    24] loss: 0.0095593666\n",
            "[43,    24] loss: 0.0105433508\n",
            "[44,    24] loss: 0.0088994907\n",
            "[45,    24] loss: 0.0087932606\n",
            "[46,    24] loss: 0.0084463129\n",
            "[47,    24] loss: 0.0078498464\n",
            "[48,    24] loss: 0.0082526386\n",
            "[49,    24] loss: 0.0079194878\n",
            "[50,    24] loss: 0.0069201678\n",
            "[51,    24] loss: 0.0071227164\n",
            "[52,    24] loss: 0.0075380033\n",
            "[53,    24] loss: 0.0068766925\n",
            "[54,    24] loss: 0.0074400440\n",
            "[55,    24] loss: 0.0086208891\n",
            "[56,    24] loss: 0.0084121654\n",
            "[57,    24] loss: 0.0077403958\n",
            "[58,    24] loss: 0.0061402084\n",
            "[59,    24] loss: 0.0080028755\n",
            "[60,    24] loss: 0.0063746104\n",
            "[61,    24] loss: 0.0069542988\n",
            "[62,    24] loss: 0.0067237157\n",
            "[63,    24] loss: 0.0067735078\n",
            "[64,    24] loss: 0.0062367305\n",
            "[65,    24] loss: 0.0062416916\n",
            "[66,    24] loss: 0.0093111010\n",
            "[67,    24] loss: 0.0077177035\n",
            "[68,    24] loss: 0.0068938461\n",
            "[69,    24] loss: 0.0075427103\n",
            "[70,    24] loss: 0.0056773062\n",
            "[71,    24] loss: 0.0076839821\n",
            "[72,    24] loss: 0.0054797789\n",
            "[73,    24] loss: 0.0048869334\n",
            "[74,    24] loss: 0.0046408834\n",
            "[75,    24] loss: 0.0041254213\n",
            "[76,    24] loss: 0.0043654530\n",
            "[77,    24] loss: 0.0067905755\n",
            "[78,    24] loss: 0.0054950498\n",
            "[79,    24] loss: 0.0039881988\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}